+++
title = 'Denoising Diffusion Probabilistic Models(DDPM) reivew'
+++

# Denoising Diffusion Probabilistic Models
ì°¸ê³  ë§í¬
+ Diffusion Model ìˆ˜í•™ì´ í¬í•¨ëœ tutorial : https://www.youtube.com/watch?v=uFoGaIVHfoE
+ learn open cvì—ì„œ ì˜¬ë¦° í¬ìŠ¤íŠ¸ : https://learnopencv.com/denoising-diffusion-probabilistic-models/

Paper
+ https://arxiv.org/pdf/2006.11239.pdf

#### ë…¼ë¬¸ì—ì„œì˜ ì•„ì´ë””ì–´
+ ë°ì´í„°ì— ë§¤ìš° ì‘ì€ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” processë¥¼ ì¤‘ì²©í•´ì„œ í•´ì£¼ë©´ normal distribution ê¹Œì§€ ë³´ë‚¼ ìˆ˜ ìˆë‹¤.
+ ê·¸ë¦¬ê³  ì´ê²ƒì„ ë§ˆì°¬ê°€ì§€ë¡œ ìˆœì°¨ì ìœ¼ë¡œ denoising í•´ì¤˜ ì´ë¯¸ì§€ë¥¼ ë³µì›í•  ìˆ˜ ìˆë‹¤.

#### í•´ì•¼í•  ê²ƒ
1. forward : noiseì˜ ì¤‘ì²©ì„ ì–´ë–»ê²Œ í‘œí˜„í•  ê²ƒì¸ì§€?
2. backward : noisingê³¼ì •ì„ ì–´ë–»ê²Œ íŒŒë¼ë¯¸í„°í™” í•´ì„œ lossë¥¼ êµ¬í•˜ê³  backpropaí•  ê²ƒì¸ê°€?

#### ì–´ë–»ê²Œ?
1. markov chainì„ ê°€ì •í•˜ì—¬ noiseì˜ ì¤‘ì²©ì„ ì„¤ëª…

2. variational inferenceë¥¼ ì´ìš©í•´ noisingì„ ì„¤ëª…í•˜ê³ , reparameterí™” í•˜ì—¬ì„œ lossë¥¼ êµ¬ì„±í•˜ì˜€ë‹¤
    + VIë€, êµ¬í•˜ê³ ìí•˜ëŠ” posteriorë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ì–´ ê°„ì ‘ì ìœ¼ë¡œ ì•Œê³ ìˆëŠ” ë¶„í¬ë¥¼ í†µí•´ lower boundë¥¼ ìµœëŒ€í™” í•˜ëŠ” ë°©ë²•ì´ë‹¤.



<img src="https://drive.google.com/uc?id=1DzU3eReh-eNBS8GsO7tVU5hfAuhdqhnj" width=300>  

ì´ì œ, ê·¸ ì–´ë–»ê²Œì— ëŒ€í•´ ì¢€ë” ìì„¸í•˜ê²Œ ì•Œì•„ë³´ì

<img src="https://drive.google.com/uc?id=19lhFdBzXRkc7Z9_0wOffcPXxnfJk0ZL8">  




#### ìˆ˜ì‹ ì •ë¦¬
+ $x_0$ : ì‹¤ì œ ì´ë¯¸ì§€
+ $x_t$ : të²ˆì˜ ë…¸ì´ì¦ˆê°€ ì¤‘ì²© ëœ ì´ë¯¸ì§€($x_T$ëŠ” nomal distributionì´ ëœë‹¤ê³  ê°€ì •)
+ $q(x_t|x_{t-1})$ : forward process, ìŠ¤ì¼€ì¥´ë§ëœ ë¶„ì‚°ê°’ì¸ $\beta_t$ë“¤ì— ì˜í•´ ë³€í™”ë¨.
+ $q(x_{t-1}|x_t)$ : që¡œë¶€í„° ìœ ë„ëœ denoisingí•¨ìˆ˜
+ $p_\theta(x_{t-1}|x_t)$ : íŒŒë¼ë¯¸í„° $\theta$ë¥¼ í†µí•´ ê·¼ì‚¬ëœ denoisingí•¨ìˆ˜

## 1. Forward process
(ëª©í‘œ : noise ê³¼ì •ì„ ì˜ ì„¤ëª…í•˜ê¸°)


+ $q(x_t|x_{t-1}) = N(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t ğˆ)$

+ ì´ì™€ê°™ì´ êµ¬ì„±í•˜ê²Œ ë˜ë©´ forward processë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆê³ , ë‚˜ì•„ê°€ì„œ reparameterization trickì„ í†µí•´ backprobaì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
+ ì´ê²ƒì„ ì¤‘ì²©í•˜ê²Œ ë˜ë©´ ì–´ë–»ê²Œ ë˜ëŠ”ê°€?

$\alpha_t=1-\beta_t$  
$\bar{\alpha_t}=\alpha_t*\alpha_{t-1}*\cdot\cdot\cdot*\alpha_1$  
ë¼ê³  í–ˆì„ ë•Œ, ë‹¤ìŒì´ ì„±ë¦½í•œë‹¤.
+ $q(x_t|x_0) = N(x_t;\sqrt{\bar{\alpha_t}}x_0, (1-\bar{\alpha_t})I)$


(ìˆ˜ì‹ì¦ëª…)  
<img src="https://drive.google.com/uc?id=18eBqVlXZZAVebxmDT4a0ijMdGRrx9hWg" width=500>

## 2. Backward process with Loss

ìš°ì„ , ì „í†µì ì¸ diffusionì— ëŒ€í•˜ì—¬ variational inferenceë¥¼ í†µí•œ loss í…€ì´ ë‹¤ìŒê³¼ ê°™ì´ ìˆë‹¤.

+ $\mathbb{E}_q\bigg[D_{KL}(q(x_T|x_0) || p(x_T)) + \sum_{t>1}{D_{KL}(q(x_{t-1}|x_t, x_0) || p_\theta(x_{t-1}|x_t)) - \log(p_\theta(x_0|x_1))}\bigg]$

ì™¼ìª½ë¶€í„°, $L_T$, $L_{t-1}$, $L_0$ë¼ê³  ì´ì•¼ê¸°í•œë‹¤.
+ $L_T$ : ë§ˆì§€ë§‰ ê²°ê³¼ì— ëŒ€í•œ regulerization termì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” $\beta_t$ë“¤ì„ í†µí•´ ìŠ¤ìºì¥´ë§ë˜ì–´ìˆì–´ ê²°ê³¼ì ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê°’ê³¼ ì‹¤ì œ ê°€ìš°ìŠ¤ë¶„í¬ì™€ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ë©´ í•­ìƒ ë™ì¼í•˜ê²Œ ë‚˜ì™€ì„œ ìƒìˆ˜ë¡œ ì¼ì •í•´ì§„ë‹¤. ë”°ë¼ì„œ, ìƒëµì´ ê°€ëŠ¥í•˜ë‹¤.
+ $L_0$ : reverse ë§ˆì§€ë§‰ í•˜ê³ ë‚˜ì„œ ì‹¤ì œì´ë¯¸ì§€ì™€ì˜ reconstruction termì´ë‹¤. ë…¼ë¬¸ì—ì„œëŠ” í•´ë‹¹ ë¶€ë¶„ì„ lossless codelengthë¼ëŠ” í‘œí˜„ì„ í•˜ë©° í° ì˜í–¥ë ¥ì´ ì—†ëŠ” lossì—¬ì„œ ì´ë¶€ë¶„ë„ ìƒë½í–ˆë‹¤ê³  í•œë‹¤. (ì‚¬ì‹¤ ë§ˆì§€ë§‰ì— ë…¸ì´ì¦ˆ ì—„ì²­ ì¡°ê¸ˆì€ ìˆìœ¼ë‚˜ ë§ˆë‚˜í•˜ê¸´í•˜ë‹¤ ì‹¤ì œë¡œ ì½”ë“œì—ì„œë„ samplingí•  ë•Œ ë§ˆì§€ë§‰ termì€ ê·¸ëŒ€ë¡œ ë³´ëƒˆë‹¤.)

ì´ì œ, ì¤‘ê°„ì˜ $L_{t-1}$ì„ ìì„¸íˆ ëœ¯ì–´ë³´ì. ì—¬ê¸°ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ ë‘ê°€ì§€ë¥¼ ì•Œì•„ì•¼í•œë‹¤.

1. $q(x_{t-1}|x_t, x_0)$
2. $p_\theta(x_{t-1}|x_t)$

__qêµ¬í•˜ê¸°__

ë¨¼ì €, $x_{t-1}$ì„ $x_t, x_0$ì—ì„œ ë¹„ë¡¯ëœ í‰ê·  ë¶„ì‚°ìœ¼ë¡œë¶€í„° samplingí•˜ëŠ” ê²ƒì´ë¼ê³  ìƒê°í•˜ë©´, ë‹¤ìŒì˜ ì‹ì„ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤.

(ì—¬ê¸°ì„  ë¶„ì‚°ì€ ìŠ¤ì¼€ì¤„ëœ ê²ƒì„ ì´ìš©í•œë‹¤)  
$q(x_{t-1}|x_t, x_0) = N(x_{t-1};\tilde{\mu_t}(x_t, x_0), \tilde{\beta_t}I)$  


(where)  
$\tilde{\mu_t}(x_t, x_0) = \cfrac{\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_t}\beta_t x_0 + \cfrac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t} x_t$  
$\tilde{\beta_t} = \cfrac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t$

që¡œë¶€í„° ìœ ë„ë˜ì–´, $x_t$ì—ì„œ $x_0$ê¹Œì§€ ì–¼ë§Œí¼ interpolationí•œ ê³³ì—ì„œ samplingí•  ê²ƒì¸ê°€ ë¼ê³  ì˜ë¯¸ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤

__pêµ¬í•˜ê¸°__

ê·¸ëŸ¬ë©´, ì´ ê°’ì„ ì£¼ì–´ì§„ íŒŒë¼ë¯¸í„° $\theta$ë¡œ í•¨ìˆ˜ $p_\theta(\cdot)$ë¥¼ ì–´ë–»ê²Œ êµ¬ì„±í•  ê²ƒì¸ê°€ê°€ ì¤‘ìš”í•œ ë¬¸ì œì´ë‹¤.

$p_\theta(x_{t-1}|x_t) = N(x_{t-1};\mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$ì´ì™€ ê°™ì´ í‰ê· ê³¼ ë¶„ì‚°ì— ëŒ€í•´ íŒŒë¼ë¯¸í„°í™” í•  ìˆ˜ ìˆë‹¤.

ì—¬ê¸°ì—ì„œë„ ì•ê³¼ê°™ì´ ë¶„ì‚°ì€ í•™ìŠµí•˜ì§€ì•Šê³  í‰ê· ë§Œ í•™ìŠµí•œë‹¤ê³  í•˜ë©´,
+ $\Sigma_\theta(x_t, t) = \sigma_t^2I$

ê·¸ë¦¬ê³ ,
+ $\sigma_t^2 = \tilde{\beta_t} = \cfrac{1-\tilde{\alpha}_{t-1}}{1-\tilde{\alpha}_t} \beta_t$
+ $\sigma_t^2 = \beta_t$

ë‹¤ìŒì˜ ê´€ê³„ê°€ ì„±ë¦½í•¨ì„ ì‹¤í—˜ì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤. ê·¸ëŸ¬ë©´, ë¶„ì‚°ì„ ê°™ê²Œ í–ˆìœ¼ë‹ˆ  
 ì´ì œ ì´ í‰ê· ì„ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ì§€ê°€ ê´€ê±´ì´ë‹¤. ê²°êµ­ ê°ê°ì˜ í‰ê· ë§Œ ì˜ ê°™ì•„ì§€ë„ë¡ í•˜ë©´ëœë‹¤!!

(ìˆ˜ì‹ ìœ ë„)  
<img src="https://drive.google.com/uc?id=18PvMsHAh4VvKUIQlOFmiqwYDLXZlKnTd" width=600>  
<img src="https://drive.google.com/uc?id=1ga4TFfOKed84ZWZMnYQhZEGzJBNDNWWh" width=550>  


ì´ ë…¼ë¬¸ì—ì„œ ë‚˜ë¦„ í‚¤í¬ì¸íŠ¸ë¼ê³  ìƒê°í•¨. í‰ê· ì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ì•„ë‹ˆë¼, ì”ì°¨ ($\epsilon$ì„ í•™ìŠµí•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ìœ ë„í•œë‹¤.)   
ê·¸ë˜ì„œ, $\tilde{\mu}(x_t, x_0)$ termì—ì„œ, ì´ $x_0$ëŒ€ì‹ ì— ë°‘ì—ì™€ ê°™ì´ reparameterization trickì„ ì‚¬ìš©í•  ë•Œì˜ ì…ì‹¤ë¡  ê°’ì„ í•™ìŠµí•˜ê³ ìí•˜ëŠ” ê°’ìœ¼ë¡œ ì¡ì€ ê²ƒì´ë‹¤!

<img src="https://drive.google.com/uc?id=1vEHzIul1idE9IV0bcO0fZR99-fHgpxd1" width=550>  
<img src="https://drive.google.com/uc?id=1OPetvGvtNxf5Wn6aZOYMQaQ_mtDEHZFn" width=600>

ìµœì¢…ì ìœ¼ë¡œ ë‹¨ìˆœí™”í•œ lossëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
$$L_{simple}(\theta) = \mathbb{E}_{t, x_0, \epsilon}\bigg[||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon, t)||^2\bigg]$$

ì¶”ê°€ì ìœ¼ë¡œ, ì´ ë…¼ë¬¸ì—ì„  $\theta$ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ U-Netì„ ì´ìš©í–ˆë‹¤ê³ í•˜ê³ , time step të¥¼ ì˜ ì„ë² ë”©í•˜ê¸° ìœ„í•´ self-attentionê¸°ìˆ ì„ ì´ìš©í–ˆë‹¤ê³  í•œë‹¤.

<img src="https://drive.google.com/uc?id=1w1l3-VYiEOGHRewha7adMM8HC-ZkklG8" height=200>

samplingê³¼ì •ì—ì„œì˜ denoisingì´ ê²°ê³¼ì ìœ¼ë¡œ ë³´ë‹ˆ, scoreê¸°ë°˜ Langevin danamicsì™€ ë™ì¼í•˜ë‹¤ê³ ë„ ë³¼ ìˆ˜ ìˆë‹¤.

## ì‹¤ìŠµí–ˆë˜ ì½”ë“œë“¤


```python
# import cv2
# from datetime import datatime

import gc, os, math, base64, random
import numpy as np
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
from torch.cuda import amp

import torch.nn.functional as F
from torch.optim import Adam, AdamW
from torch.utils.data import Dataset, DataLoader

import torchvision
import torchvision.transforms as TF
import torchvision.datasets as datasets
from torchvision.utils import make_grid


from IPython.display import display, HTML, clear_output
```


```python
class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, total_time_steps=1000, time_emb_dims=128, time_emb_dims_exp=512):
        super().__init__()

        half_dim = time_emb_dims // 2

        emb = math.log(10000) / (half_dim - 1)
        emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)

        ts = torch.arange(total_time_steps, dtype=torch.float32)

        emb = torch.unsqueeze(ts, dim=-1) * torch.unsqueeze(emb, dim=0)
        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)

        self.time_blocks = nn.Sequential(
            nn.Embedding.from_pretrained(emb),
            nn.Linear(in_features=time_emb_dims, out_features=time_emb_dims_exp),
            nn.SiLU(),
            nn.Linear(in_features=time_emb_dims_exp, out_features=time_emb_dims_exp),
        )

    def forward(self, time):
        return self.time_blocks(time)
```


```python
class AttentionBlock(nn.Module):
    def __init__(self, channels=64):
        super().__init__()
        self.channels = channels

        self.group_norm = nn.GroupNorm(num_groups=8, num_channels=channels)
        self.mhsa = nn.MultiheadAttention(embed_dim=self.channels, num_heads=4, batch_first=True)

    def forward(self, x):
        B, _, H, W = x.shape
        h = self.group_norm(x)
        h = h.reshape(B, self.channels, H * W).swapaxes(1, 2)
        h, _ = self.mhsa(h, h, h)
        h = h.swapaxes(2, 1).view(B, self.channels. H, W)
        return x + h
```


```python
class ResnetBlock(nn.Module):
    def __init__(self, *, in_channels, out_channels, dropout_rate=0.1, time_emb_dims=512, apply_attention=False):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels

        self.act_fn = nn.SiLU()
        # Group1?
        self.normalize_1 = nn.GroupNorm(num_groups=8, num_channels=self.in_channels)
        self.conv_1 = nn.Conv2d(in_channels=self.in_channels,
                                out_channels=self.out_channels, kernel_size=3, padding="same")

        # Group2 time embedding
        self.dense_1 = nn.Linear(in_features=time_emb_dims, out_features=self.out_channels)

        # Group3
        self.normalize_2 = nn.GroupNorm(num_groups=8, num_channels=self.out_channels)
        self.dropout = nn.Dropout2d(p=dropout_rate)
        self.conv_2 = nn.Conv2d(in_channels=self.out_channels,
                                out_channels=self.out_channels, kernel_size=3, padding="same")

        if self.in_channels != self.out_channels:
            self.match_input = nn.Conv2d(in_channels=self.in_channels,
                                         out_channels=out_channels, kernel_size=1, stride=1)
        else:
            self.match_input = nn.Identity()

        if apply_attention:
            self.attention = AttentionBlock(channels=self.out_channels)
        else:
            self.attention = nn.Identity()

    def forward(self, x, t):
        # Group1
        h = self.act_fn(self.normalize_1(x))
        h = self.conv_1(h)

        # Group2
        # add in timestep embedding
        h += self.dense_1(self.act_fn(t))[:, :, None, None]    # 2ì°¨ì›ì§œë¦¬ 4ì°¨ì›ìœ¼ë¡œ(unsqueeze?)

        # Group3
        h = self.act_fn(self.normalize_2(h))
        h = self.dropout(h)
        h = self.conv_2(h)

        return h
```


```python
class DownSample(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.downsample = nn.Conv2d(in_channels=channels, out_channels=channels,
                                   kernel_size=3, stride=2, padding=1)

    def forward(self, x, *args):
        return self.downsample(x)

class UpSample(nn.Module):
    def __init__(self, in_channels):
        super().__init__()

        self.upsample = nn.Sequential(nn.Upsample(scale_factor=2, mode="nearest"),
                                     nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1),
                                     )

    def forward(self, x, *args):
        return self.upsample(x)
```


```python
class UNet(nn.Module):
    def __init__(
    self,
    input_channels=3,    # RGB 3ê°œì— ëŒ€í•œ í‰ê· 
    output_channels=3,
    num_res_blocks=2,
    base_channels=64,
    base_channels_multiples=(1, 2, 2, 4),
    apply_attention=(False, False, True, False),
    dropout_rate=0.1,
    time_multiple=4,
    ):
        super().__init__()

        time_emb_dims_exp = base_channels * time_multiple
        self.time_embeddings = SinusoidalPositionEmbeddings(time_emb_dims=base_channels,
                                                           time_emb_dims_exp=time_emb_dims_exp)

        self.first = nn.Conv2d(in_channels=input_channels, out_channels=base_channels,
                              kernel_size=3, padding="same")

        num_resolutions = len(base_channels_multiples)

        # encoder of UNet, dimension reduction part
        self.encoder_blocks = nn.ModuleList()
        curr_channels = [base_channels]
        in_channels = base_channels

        for level in range(num_resolutions):
            out_channels = base_channels * base_channels_multiples[level]

            for _ in range(num_res_blocks):

                block = ResnetBlock(
                in_channels=in_channels,
                out_channels=out_channels,
                dropout_rate=dropout_rate,
                time_emb_dims=time_emb_dims_exp,
                apply_attention=apply_attention[level],
                )
                self. encoder_blocks.append(block)

                in_channels = out_channels
                curr_channels.append(in_channels)

            if level != (num_resolutions - 1):
                self.encoder_blocks.append(DownSample(channels=in_channels))
                curr_channels.append(in_channels)

        # Bottleneck in between
        self.bottleneck_blocks = nn.ModuleList(
            (
                ResnetBlock(
                    in_channels=in_channels,
                    out_channels=in_channels,
                    dropout_rate=dropout_rate,
                    time_emb_dims=time_emb_dims_exp,
                    apply_attention=True,
                ),
                ResnetBlock(
                    in_channels=in_channels,
                    out_channels=in_channels,
                    dropout_rate=dropout_rate,
                    time_emb_dims=time_emb_dims_exp,
                    apply_attention=False,
                ),
            )
        )

        # Decoder in UNet, Dimension restoration with skip-connections ?!
        self.decoder_blocks = nn.ModuleList()

        for level in reversed(range(num_resolutions)):
            out_channels = base_channels * base_channels_multiples[level]

            for _ in range(num_res_blocks + 1):
                encoder_in_channels = curr_channels.pop()     # ì´ê±° ë§›ìˆë‹¤ ã…‹ã…‹
                block = ResnetBlock(
                    in_channels=encoder_in_channels + in_channels, # ??? -> ì•„ ì´ê±° concatí•˜ë‹ˆê¹Œ ë‹¹ì—°íˆ ë”í•´ì•¼ì§€
                    out_channels=out_channels,
                    dropout_rate=dropout_rate,
                    time_emb_dims=time_emb_dims_exp,
                    apply_attention=apply_attention[level],
                )

                in_channels = out_channels
                self.decoder_blocks.append(block)

            if level != 0:
                self.decoder_blocks.append(UpSample(in_channels))

        self.final = nn.Sequential(
        nn.GroupNorm(num_groups=8, num_channels=in_channels),
        nn.SiLU(),
        nn.Conv2d(in_channels=in_channels, out_channels=output_channels, kernel_size=3,
                 stride=1, padding="same"),
        )
    def forward(self, x, t):

        time_emb = self.time_embeddings(t)

        h = self.first(x)
        outs = [h]

        for layer in self.encoder_blocks:
            h = layer(h, time_emb)
            outs.append(h)

        for layer in self.bottleneck_blocks:
            h = layer(h, time_emb)

        for layer in self.decoder_blocks:
            if isinstance(layer, ResnetBlock):
                out = outs.pop()
                h = torch.cat([h, out], dim=1)    # skip-connection
            h = layer(h, time_emb)

        h = self.final(h)

        return h
```


```python
M = UNet()
```


```python
t = torch.randint(low=1, high=1000, size=(3,))
xt = torch.rand((3,3,64,64))
```


```python
pred_noise = M(xt, t)
```


```python
pred_noise.shape
```




    torch.Size([3, 3, 64, 64])


